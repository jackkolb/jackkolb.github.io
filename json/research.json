{
	"research":
	[
		{
			"name": "Leveraging Cognitive States in Human-Robot Teaming",
			"conference": "true",
			"authors": "<b>Jack Kolb</b>, Harish Ravichandar, and Sonia Chernova",
			"paper": "https://jackkolb.com/pdf/ROMAN_22_Leveraging_Cognitive_States_in_Human_Robot_Teaming.pdf",
			"github": "https://github.com/GT-RAIL/cognitive-states-in-human-robot-teaming",
			"tools": "Conference Proceedings of RO-MAN '22",
			"time": "2022",
			"status": "Complete",
			"short": "Measurements of user cognitive states are used to inform a role assignment algorithm and improve teaming performance.",
			"long": "[ABSTRACT] Mixed human-robot teams (HRTs) have the potential to perform complex tasks by leveraging diverse and complementary capabilities within the team. However, assigning humans to operator roles in HRTs is challenging due to the significant variation in user capabilities. While much of prior work in role assignment treats humans as interchangeable (either generally or within a category), we investigate the utility of personalized models of operator capabilities based in relevant human factors in an effort to improve overall team performance. We call this approach individualized role assignment (IRA) and provide a formal definition. A key challenge for IRA is associated with the fact that factors that affect human performance are not static (e.g., one's ability to track multiple objects can change during or between tasks). Instead of relying on time-consuming and highly-intrusive measurements taken during the execution of tasks, we propose the use of short cognitive tests, taken before engaging in human-robot tasks, and predictive models of individual performance to perform IRA. Results from a comprehensive user study conclusively demonstrate that IRA leads to significantly better team performance than a baseline method that assumes human operators are interchangeable, even when we control for the influence of the robots' performance. Further, our results point to the possibility that such relative benefits of IRA will increase as the number of operators (i.e., choices) increase for a fixed number of tasks."
		},

		{
			"name": "Safe Dexterous Manipulation Using Geometric Boundary Constraints",
			"workshop": "true",
			"authors": "Abhineet Jain, <b>Jack Kolb</b>, and Harish Ravichandar",
			"paper": "https://jackkolb.com/pdf/IJCAI_22_Constrained_RL_for_Dexterous_Manipulation.pdf",
			"tools": "Workshop Proceedings of IJCAI '22 (Safe RL, non-archival)",
			"time": "2022",
			"status": "Complete",
			"short": "Instance-specific geometric boundary constraints are used with reinforcement learning algorithms to obtain safe high-dimensional robot hand manipulation.",
			"long": "[ABSTRACT] We explore adding instance-specific constraints to an object relocation task, that restrict and guide the robot's behavior during training as well as roll outs. Constrained Policy Optimization (CPO) is an effective method to solve constrained MDPs, built upon trust-region policy optimization (TRPO). We formulate a cylindrical boundary constraint for the initial motion of the robot hand towards the object. The robot incurs a penalty when it moves outside the boundary. We find that using CPO with this simple geometric constraint can ensure the robot learns to move towards the object sooner than without constraints. Further, training with this constraint (CPO) requires a similar number of samples as its unconstrained counterpart (TRPO) to master the skill. These findings shed light on how simple constraints can help robots achieve sensible and safe behavior quickly and ease concerns surrounding hardware deployment. We also investigate the effects of the strictness of these constraints and report findings that provide insights into how different degrees of strictness affect learning outcomes."
		},

		{
			"name": "Evaluating the Effectiveness of Corrective Demonstrations and a Low-Cost Sensor for Dexterous Manipulation",
			"authors": "*Abhineet Jain, *<b>Jack Kolb</b>, J.M. Abbess IV, and Harish Ravichandar",
			"paper": "https://arxiv.org/pdf/2204.07631.pdf",
			"github": "https://github.com/GT-STAR-Lab/corrective-demos-dexterous-manipulation",
			"workshop": "true",
			"tools": "Workshop Proceedings of HRI '21 (MLHRC, non-archival)",
			"time": "2022",
			"status": "Complete",
			"short": "Explores the use of DAGGER-like corrections, and demonstrations from a low-cost pose sensor, to improve robot hand performance at a \"pick and place\" task.",
			"long": "[ABSTRACT] Imitation learning is a promising approach to help robots acquire dexterous manipulation capabilities without the need for a carefully-designed reward or a significant computational effort. However, existing imitation learning approaches require sophisticated data collection infrastructure and struggle to generalize beyond the training distribution. One way to address this limitation is to gather additional data that better represents the full operating conditions. In this work, we investigate characteristics of such additional demonstrations and their impact on performance. Specifically, we study the effects of <i>corrective</i> and <i>randomly-sampled</i> additional demonstrations on learning a policy that guides a five-fingered robot hand through a pick-and-place task. Our results suggest that corrective demonstrations considerably outperform randomly-sampled demonstrations, when the proportion of additional demonstrations sampled from the full task distribution is larger than the number of original demonstrations sampled from a restrictive training distribution. Conversely, when the number of original demonstrations are higher than that of additional demonstrations, we find no significant differences between corrective and randomly-sampled additional demonstrations. These results provide insights into the inherent trade-off between the effort required to collect corrective demonstrations and their relative benefits over randomly-sampled demonstrations. Additionally, we show that inexpensive vision-based sensors, such as LeapMotion, can be used to dramatically reduce the cost of providing demonstrations for dexterous manipulation tasks."
		},

		{
			"name": "Predicting Individual Human Performance in Human-Robot Teaming",
			"authors": "<b>Jack Kolb</b>, Mayank Kishore, Kenneth Shaw, Harish Ravichandar, and Sonia Chernova",
			"paper": "https://jackkolb.com/pdf/ROMAN_21_Predicting_Individual_Performance_in_Human_Robot_Teaming.pdf",
			"conference": "true",
			"tools": "Conference Proceedings of RO-MAN '21",
			"time": "2021",
			"status": "Complete",
			"short": "Through a user study we find that scores from user cognitive skill tests can correlate to performance at robot teleoperation tasks.",
			"long": "[ABSTRACT] Coordinating human-robot teams requires careful planning and allocation of tasks to the most appropriate agents.  This challenge is exacerbated by the fact that, unlike their robot teammates, humans exhibit significant variation in their abilities. Existing work largely ignores this variation in favor of simpler aggregate models, failing to leverage specialized capabilities of different individuals. In this work, we introduce simple cognitive tests for measuring inherent variations in human capabilities related to human-robot teaming, specifically, the ability to maintain situational awareness and to mentally model latent network structures.  We then demonstrate that user study participant performance on these cognitive tests is correlated with, and thus is a predictor for, their performance on human-robot teaming tasks. These findings have the potential to improve human-robot teaming algorithms (e.g., task allocation) by providing a mechanism to better leverage individual differences in human agents."
		}
	]
}